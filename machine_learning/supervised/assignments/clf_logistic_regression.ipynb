{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Intuition\n",
    "\n",
    "The data set consists of 50 samples from each of three species of *Iris* ([Iris setosa](https://en.wikipedia.org/wiki/Iris_setosa), [Iris virginica](https://en.wikipedia.org/wiki/Iris_virginica) and [Iris versicolor](https://en.wikipedia.org/wiki/Iris_versicolor)). Four features were measured from each sample: the length and the width of the [sepals](https://en.wikipedia.org/wiki/Setal) and [petals](https://en.wikipedia.org/wiki/Petal), in centimeters.\n",
    "\n",
    "This interactive demo lets you explore the Logistic Regression algorithm for classification. The demo uses a Logistic Regression model in the Iris dataset. \n",
    "\n",
    "We can visualize the classifier decision boundary. A decision boundary is a line (in the case of two features), where all (or most) samples of one class are on one side of that line, and all samples of the other class are on the opposite side of the line. The line separates one class from the other. If you have more than two features, the decision boundary is not a line, but a (hyper)-plane in the dimension of your feature space.\n",
    "Each point in the plane is colored with the class that would be assigned to it using the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(penalty, solver, X, y, C):\n",
    "    clf = linear_model.LogisticRegression(penalty=penalty, solver=solver, C=C)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_iris() # try with another dataset \n",
    "\n",
    "X = dataset.data[:, :2]\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "cmap_light = ListedColormap([\"#e28743\", \"#42bff5\", \"#d3bff5\"][:len(dataset.target_names)])\n",
    "cmap_bold =  [\"#80391e\", \"#117ab3\", \"#33008a\"][:len(dataset.target_names)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.canvas.header_visible = True\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    hue=dataset.target_names[y],\n",
    "    palette=cmap_bold,\n",
    "    alpha=1.0,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "def plot_boundary(penalty, solver, C):\n",
    "    clf = fit_logistic(penalty,solver, X, y, C)\n",
    "    \n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X,\n",
    "        cmap=cmap_light,\n",
    "        ax=ax,\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        xlabel=dataset.feature_names[0],\n",
    "        ylabel=dataset.feature_names[1],\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X[:, 0],\n",
    "        y=X[:, 1],\n",
    "        hue=dataset.target_names[y],\n",
    "        palette=cmap_bold,\n",
    "        alpha=1.0,\n",
    "        edgecolor=\"black\",\n",
    "        legend=False\n",
    "    )\n",
    "    display(fig)\n",
    "    return clf\n",
    "\n",
    "\n",
    "inter = interactive(\n",
    "    plot_boundary,\n",
    "    penalty=[\"l2\", \"none\"],\n",
    "    solver= [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "    C = [1.0, 0.001, 0.01, 2.0, 5.0, 10.0]\n",
    ")\n",
    "\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary is draw using the sepal width and sepal length features. Recall that `penalty` prevents the logistic model from having too many variables - theoretically it results in shrinking the coefficients of the less contributive variables toward zero, the parameter `C` changes the complexity to the model.\n",
    "\n",
    "The `solver` is the optimization algorythm towards error minimization.  **Note:** not all penalties work in all solvers. \n",
    "\n",
    "Using the interactive demo try to answer the following questions:\n",
    "* What is the impact of the value of `penalty`, `solver` and `C` in the prediction? How do they relate to the bias-variance tradeoff?\n",
    "\n",
    "* Do the different criterion have great impact on model performance?\n",
    "\n",
    "* Why are the decision boundaries straight lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Train and Test\n",
    "In the next section you will use the Logistic Regression classifier to make predictions on the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the dataset in training and testing. Use a test_size of 33%\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instantiate a Logistic Regression classifier with default parameters\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use the classifier to predict the test set.\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the classifier error on the test set (also known as hold-out evaluation)\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra - Inspect the misclassification(s)\n",
    "\n",
    "Run the code below and inspect the model's misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongs = np.where((y_pred == y_test) == False)[0]\n",
    "print(f\"There are {len(wrongs)} wrong predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    hue=dataset.target_names[y],\n",
    "    palette=cmap_bold,\n",
    "    alpha=1.0,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "plt.scatter(    \n",
    "    x=X_test[wrongs, 0],\n",
    "    y=X_test[wrongs, 1],\n",
    "    color=[cmap_bold[i] for i in y_pred[wrongs]],\n",
    "    marker=\"+\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv-clf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddea36be15bf088bb1b18514e6cb4beef2a8eecc3bb099944a045ee7fe14ddf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
