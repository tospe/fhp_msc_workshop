{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Intuition\n",
    "\n",
    "The data set consists of 50 samples from each of three species of *Iris* ([Iris setosa](https://en.wikipedia.org/wiki/Iris_setosa), [Iris virginica](https://en.wikipedia.org/wiki/Iris_virginica) and [Iris versicolor](https://en.wikipedia.org/wiki/Iris_versicolor)). Four features were measured from each sample: the length and the width of the [sepals](https://en.wikipedia.org/wiki/Setal) and [petals](https://en.wikipedia.org/wiki/Petal), in centimeters.\n",
    "\n",
    "This interactive demo lets you explore the Suport Vector Machine algorithm for classification. The demo uses a Suport Vector Machine model in the Iris dataset. \n",
    "\n",
    "We can visualize the classifier decision boundary. A decision boundary is a line (in the case of two features), where all (or most) samples of one class are on one side of that line, and all samples of the other class are on the opposite side of the line. The line separates one class from the other. If you have more than two features, the decision boundary is not a line, but a (hyper)-plane in the dimension of your feature space.\n",
    "Each point in the plane is colored with the class that would be assigned to it using the Support Vector Machine model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svm(kernel, X, y, C, degree):\n",
    "    clf = svm.SVC(kernel=kernel, C=C, degree=degree)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_iris()#.load_breast_cancer() # you try with another dataset \n",
    "\n",
    "X = dataset.data[:, :2]\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary is draw using the sepal width and sepal length features. Recall that `kernel` gives the \"shape\" of the decision boundary and there are several examples in the sklearn. If the chosen `kernel` is polymonial (poly), you can choose the `degree` parameter, that changes the order of the polymonial algorythm for the decision of the SVM model (sklearn ignores when polymonial is not chosen). Like the Logistic Regression the parameter `C` changes the complexity to the model.\n",
    "\n",
    "\n",
    "Using the interactive demo try to answer the following questions:\n",
    "* What is the impact of different values of `degree` if the `kernel` is **poly** in the prediction? How do they relate to the bias-variance tradeoff?\n",
    "\n",
    "* Do the different criterion have great impact on model performance?\n",
    "\n",
    "* What are the `kernel`s which the boundaries are not straight lines? Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color maps\n",
    "\n",
    "cmap_light = ListedColormap([\"#e28743\", \"#42bff5\", \"#d3bff5\"][:len(dataset.target_names)])\n",
    "cmap_bold =  [\"#80391e\", \"#117ab3\", \"#33008a\"][:len(dataset.target_names)]\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.canvas.header_visible = True\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    hue=dataset.target_names[y],\n",
    "    palette=cmap_bold,\n",
    "    alpha=1.0,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "def plot_boundary(kernel, C, degree):\n",
    "    clf = fit_svm(kernel, X, y, C, degree)\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X,\n",
    "        cmap=cmap_light,\n",
    "        ax=ax,\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        xlabel=dataset.feature_names[0],\n",
    "        ylabel=dataset.feature_names[1],\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X[:, 0],\n",
    "        y=X[:, 1],\n",
    "        hue=dataset.target_names[y],\n",
    "        palette=cmap_bold,\n",
    "        alpha=1.0,\n",
    "        edgecolor=\"black\",\n",
    "        legend=False\n",
    "    )\n",
    "        # Plot also the training point\n",
    "    display(fig)\n",
    "    return clf\n",
    "\n",
    "\n",
    "inter = interactive(\n",
    "    plot_boundary,\n",
    "    kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    degree=[1, 2, 3, 5, 10],\n",
    "    C=[1, 0.01, 0.1, 5, 10]\n",
    ")\n",
    "\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Train and Test\n",
    "In the next section you will use the SVM classifier to make predictions on the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the dataset in training and testing. Use a test_size of 33%\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instantiate a SVM with default parameters\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use the classifier to predict the test set.\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the classifier error on the test set (also known as hold-out evaluation)\n",
    "# Hint: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra - Inspect the misclassification(s)\n",
    "\n",
    "Run the code below and inspect the model's misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongs = np.where((y_pred == y_test) == False)[0]\n",
    "print(f\"There are {len(wrongs)} wrong predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    hue=dataset.target_names[y],\n",
    "    palette=cmap_bold,\n",
    "    alpha=1.0,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "plt.scatter(    \n",
    "    x=X_test[wrongs, 0],\n",
    "    y=X_test[wrongs, 1],\n",
    "    color=[cmap_bold[i] for i in y_pred[wrongs]],\n",
    "    marker=\"+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv-clf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddea36be15bf088bb1b18514e6cb4beef2a8eecc3bb099944a045ee7fe14ddf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
